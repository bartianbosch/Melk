{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Big Data Milk.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bartianbosch/Melk/blob/main/Big_Data_Milk_Oscar.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zSVRLt9dJyKM"
      },
      "source": [
        "Big Data Groupwork Milk\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o3LZGS6nWtSx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aeeff03a-cd45-43a0-b6cd-90960eb0bc35"
      },
      "source": [
        "## To download and update the necessary requirements initialize Apache Spark, run this cell\n",
        "!apt-get update\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q http://downloads.apache.org/spark/spark-2.4.7/spark-2.4.7-bin-hadoop2.7.tgz\n",
        "!tar xf spark-2.4.7-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark\n",
        "\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-2.4.7-bin-hadoop2.7\"\n",
        "\n",
        "import findspark\n",
        "findspark.init()\n",
        "from pyspark.sql import SparkSession\n",
        "sp = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
        "\n",
        "from pyspark import SparkContext\n",
        "from pyspark.sql import SparkSession\n",
        "sc = SparkContext.getOrCreate()\n",
        "spark = SparkSession.builder.getOrCreate()\n",
        "\n",
        "from pyspark.sql import SQLContext\n",
        "sqlContext = SQLContext(sc)\n",
        "\n",
        "# Added our own necessary imports \n",
        "import seaborn as sns\n",
        "\n",
        "from pyspark import SparkFiles\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "plt.close('all')\n",
        "plt.rcParams['figure.figsize'] = [30, 20]\n",
        "\n",
        "from pyspark.sql import types, Window\n",
        "from pyspark.sql import functions as psf\n",
        "from pyspark.sql.functions import col, unix_timestamp, to_date\n",
        "from pyspark.ml.feature import VectorAssembler, StringIndexer, OneHotEncoderEstimator\n",
        "\n",
        "from pyspark.ml import Pipeline\n",
        "\n",
        "from pyspark.ml.regression import LinearRegression, LinearRegressionModel\n",
        "\n",
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "\n",
        "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
        "\n",
        "import sys\n",
        "\n",
        "\n",
        "# Mounting drive\n",
        "from google.colab import drive, files\n",
        "#drive.mount('/content/gdrive/')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0% [Working]\r            \rHit:1 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease\n",
            "Ign:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Ign:3 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:4 http://security.ubuntu.com/ubuntu bionic-security InRelease\n",
            "Hit:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "Hit:6 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Hit:7 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n",
            "Hit:8 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Hit:10 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Hit:12 http://archive.ubuntu.com/ubuntu bionic-updates InRelease\n",
            "Hit:13 http://archive.ubuntu.com/ubuntu bionic-backports InRelease\n",
            "Reading package lists... Done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BMSmDG4GLso4"
      },
      "source": [
        "Loading the data into a DF\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5eQ2_oU-GC_1"
      },
      "source": [
        "## Loading the data\n",
        "\n",
        "fileName = 'ff_dairy_v1.csv'\n",
        "if not os.path.isfile(fileName):\n",
        "  uploaded = files.upload()\n",
        "\n",
        "# Prepare and load the file into a spark rdd\n",
        "spark.sparkContext.addFile(fileName)\n",
        "milk_rdd = spark.read.csv(SparkFiles.get(fileName), header=True)\n",
        "milk_rdd = milk_rdd.repartitionByRange(\"Cow number\")\n",
        "print(\"Number of partitions: \", milk_rdd.rdd.getNumPartitions())\n",
        "\n",
        "# Also load the data to a pandas table, just in case we need it for testing.\n",
        "milk_pd=pd.read_csv(fileName, encoding='latin1')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fDwnD2s2W-H-"
      },
      "source": [
        "# To check spark rdd, uncomment the following line:\n",
        "#milk_rdd.show(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vFz1OVe9gzl-"
      },
      "source": [
        "# To check pandas dataframe, uncomment the following line:\n",
        "#milk_pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iCd12fxv0q5P"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "## Creating a Machine Learning Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pMloXHglEdhH"
      },
      "source": [
        "### Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nsBJhDIZRAEg"
      },
      "source": [
        "## Renaming the columns with the unusable characters\n",
        "\n",
        "newColumnNames = list(map(lambda x: x.replace(\".\",\"\").replace(\"�C\",\"degC\").replace(\"�I\",\"plusI\"), milk_rdd.columns))\n",
        "\n",
        "milk_rdd2 = milk_rdd.toDF(*newColumnNames)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bgm-WDfsu1Yz"
      },
      "source": [
        "## Fixing the RDD columns datatypes\n",
        "\n",
        "# We need to change the datatype of each column in the rdd, to be able to\n",
        "# process it correctly.\n",
        "\n",
        "# Creating a function to set the given columns to the given datatype.\n",
        "def fixType(datasetName, colName, dataType):\n",
        "  \"\"\"Takes a dataset and returns the dataset with the given column set to the given dataype\"\"\"\n",
        "  return datasetName.withColumn(colName, psf.col(colName).cast(dataType))\n",
        "\n",
        "# Preparing Lists with the column names according to which type they need to be.\n",
        "allColumns = ['Cow number', 'Date', 'Barn', 'Barn part', 'Treatment', 'Lactation number', 'Days in milk', 'Day number', 'Week', 'Period (VP = preperiod, HP = trial period)', 'Period part (VP = preperiod, HP = trial period)', 'Intake basal ration (kg dm)', 'Intake total ration (kg dm)', 'Water intake (kg)', 'Concentrate intake (kg)', 'Weight (kg)', 'BCS', 'Backfat Thickness', 'Milk yield (kg)', 'Fat%', 'Protein%', 'Urea (mg/kg)', 'SCC (*1000/ml)', 'Lactose%', 'Avg Temperature (degC)', 'Air speed', 'Max temperature (degC)', 'Rumination time (min/day)', 'Avg pH', 'Avg Rumen Temperature ', 'Time pH<5,8 (h)', 'Manure consistency (1=fluid, 5= hard)', 'Manure fibre score (1=short, 5 = long)', 'Number of kernels', 'Manure sieving residu (%)', 'Manure dm (g/kg OM)', 'Manure starch (g/kg dm)', 'Urin-pH', 'Intake pre-period (kg dm)', 'Milk yield prepreriod (kg)', 'Fat% preperiod', 'Protein% preperiod', 'Fat preperiod (kg)', 'Protein preperiod (kg)', 'ECM preperiod (kg)', 'ECM (kg)', 'Crude fiber (g/day)', 'Sugar (g/day)', 'Crude protein (g/day)', 'Crude fat (g/day)', 'Starch (g/day)', 'Ca (g/day)', 'P (g/day)', 'Na (g/day)', 'Cl (g/day)', 'K (g/day)', 'Mg (g/day)', 'nXP (g/day)', 'RNB (g/day)', 'MELK (g/day)', 'NEL (g/day)', 'WDE (g/day)', 'EKB (g/day)', 'WDS (g/day)', 'SPK (g/day)', 'TPK (g/day)', 'SPE (g/day)', 'TPE (g/day)', 'plusI (/day)', 'WI (/day)', 'GP (g/day)', 'Crude fiber (g/kg dm)', 'Sugar (g/kg dm)', 'Crude protein (g/kg dm)', 'Crude fat (g/kg dm)', 'Starch (g/kg dm)', 'Ca (g/kg dm)', 'P (g/kg dm)', 'Na (g/kg dm)', 'Cl (g/kg dm)', 'K (g/kg dm)', 'Mg (g/kg dm)', 'nXP (g/kg dm)', 'RNB (g/kg dm)', 'MELK (/kg dm)', 'NEL (MJ/kg dm)', 'WDE (g/kg dm)', 'EKB (g/kg dm)', 'WDS (g/kg dm)', 'SPK (g/kg dm)', 'TPK (g/kg dm)', 'SPE (g/kg dm)', 'TPE (g/kg dm)', 'plusI (/kg dm)', 'WI (/kg dm)', 'GP (g/kg dm)']\n",
        "doubleColumns = ['Intake basal ration (kg dm)', 'Intake total ration (kg dm)', 'Water intake (kg)', 'Concentrate intake (kg)', 'Weight (kg)', 'BCS', 'Milk yield (kg)', 'Fat%', 'Protein%', 'Lactose%', 'Avg Temperature (degC)', 'Air speed', 'Max temperature (degC)', 'Avg pH', 'Avg Rumen Temperature ', 'Time pH<5,8 (h)', 'Number of kernels', 'Manure sieving residu (%)', 'Manure starch (g/kg dm)', 'Urin-pH', 'Intake pre-period (kg dm)', 'Milk yield prepreriod (kg)', 'Fat% preperiod', 'Protein% preperiod', 'Fat preperiod (kg)', 'Protein preperiod (kg)', 'ECM preperiod (kg)', 'ECM (kg)']\n",
        "intColumns = ['Cow number', 'Barn', 'Barn part', 'Lactation number', 'Days in milk', 'Day number', 'Week', 'Backfat Thickness', 'Urea (mg/kg)', 'SCC (*1000/ml)', 'Rumination time (min/day)', 'Manure consistency (1=fluid, 5= hard)', 'Manure fibre score (1=short, 5 = long)', 'Manure dm (g/kg OM)', 'Crude fiber (g/day)', 'Sugar (g/day)', 'Crude protein (g/day)', 'Crude fat (g/day)', 'Starch (g/day)', 'Ca (g/day)', 'P (g/day)', 'Na (g/day)', 'Cl (g/day)', 'K (g/day)', 'Mg (g/day)', 'nXP (g/day)', 'RNB (g/day)', 'MELK (g/day)', 'NEL (g/day)', 'WDE (g/day)', 'EKB (g/day)', 'WDS (g/day)', 'SPK (g/day)', 'TPK (g/day)', 'SPE (g/day)', 'TPE (g/day)', 'plusI (/day)', 'WI (/day)', 'GP (g/day)', 'Crude fiber (g/kg dm)', 'Sugar (g/kg dm)', 'Crude protein (g/kg dm)', 'Crude fat (g/kg dm)', 'Starch (g/kg dm)', 'Ca (g/kg dm)', 'P (g/kg dm)', 'Na (g/kg dm)', 'Cl (g/kg dm)', 'K (g/kg dm)', 'Mg (g/kg dm)', 'nXP (g/kg dm)', 'RNB (g/kg dm)', 'MELK (/kg dm)', 'NEL (MJ/kg dm)', 'WDE (g/kg dm)', 'EKB (g/kg dm)', 'WDS (g/kg dm)', 'SPK (g/kg dm)', 'TPK (g/kg dm)', 'SPE (g/kg dm)', 'TPE (g/kg dm)', 'plusI (/kg dm)', 'WI (/kg dm)', 'GP (g/kg dm)']\n",
        "stringColumn = ['Treatment', 'Period (VP = preperiod, HP = trial period)', 'Period part (VP = preperiod, HP = trial period)']\n",
        "\n",
        "\n",
        "# Setting the columns to the correct type\n",
        "for colName in doubleColumns:\n",
        "  milk_rdd2 = fixType(milk_rdd2, colName, \"double\")\n",
        "for colName in intColumns:\n",
        "  milk_rdd2 = fixType(milk_rdd2, colName, \"int\")\n",
        "#milk_rdd2 = milk_rdd2.withColumn(\"Date\", psf.col(\"Date\").cast(\"date\"))\n",
        "milk_rdd2 = milk_rdd2.withColumn(\"Date\",\n",
        "                                 to_date(unix_timestamp(col('Date'), 'dd/MM/yy').cast(\"timestamp\")))\n",
        "\n",
        "# Uncomment the next line to check the schema\n",
        "#milk_rdd2.printSchema()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AM5UfQQx0qbE"
      },
      "source": [
        "## Create the vectorizer that adds the features column needed to run the machine learning pipeline\n",
        "\n",
        "### To change on which columns the LR model is build you only need to change ###\n",
        "### the 2 variables: inputColNames and labelColName ###\n",
        "\n",
        "# Columns that should not be in the linear regression model\n",
        "doNotInput = ['Cow number', 'Date', 'Barn', 'Barn part']\n",
        "\n",
        "# Columns used as input for the LR model. Previously used are comented for ease of testing.\n",
        "#inputColNames = ['Protein preperiod (kg)','Crude fat (g/kg dm)','Protein%','Protein% preperiod','Fat%','Fat% preperiod']\n",
        "#inputColNames = ['Water intake (kg)','Fat%', 'Protein%', 'Lactose%','Urea (mg/kg)', 'SCC (*1000/ml)']\n",
        "#inputColNames = doubleColumns[0:10]\n",
        "#inputColNames = intColumns\n",
        "inputColNames = doubleColumns + intColumns + [f'{col}_encoded' for col in stringColumn]\n",
        "#inputColNames = [x for x in allColumns if x not in doNotInput]\n",
        "\n",
        "\n",
        "print(inputColNames)\n",
        "\n",
        "# The name of the column which value you want to predict.\n",
        "labelColName = \"Milk yield (kg)\"\n",
        "\n",
        "# Generating the name column which will be filled with the predicted values.\n",
        "predictionColName = \"Predicted \" + labelColName\n",
        "\n",
        "# Removing the label column from the input column if it ended in there on accident\n",
        "if labelColName in inputColNames: inputColNames.remove(labelColName)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CNPiZnBtXHKd"
      },
      "source": [
        "### TEMPORARY FIX, BECAUSE REMOVING NA MAKES ALL VP COLLUMNS DISSAPEAR WHICH GIVES ERRORS ###\n",
        "#inputColNames.remove('Period (VP = preperiod, HP = trial period)')\n",
        "#milk_rdd2 = milk_rdd2.drop('Period (VP = preperiod, HP = trial period)').collect()\n",
        "\n",
        "print(inputColNames)\n",
        "print(milk_rdd2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5QBt3p08IFCU"
      },
      "source": [
        "# Forward fill blank values\n",
        "milk_data = milk_rdd2\n",
        "# define the window\n",
        "window = Window.partitionBy('Cow number').orderBy('Day number').rowsBetween(-sys.maxsize, 0)\n",
        "\n",
        "for column in milk_data.columns:\n",
        "  # define the forward-filled column\n",
        "  filled_column = psf.last(milk_data[column], ignorenulls=True).over(window)\n",
        "\n",
        "  # do the fill \n",
        "  milk_data = milk_data.withColumn(column,  filled_column)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mceLxQ7qIFub"
      },
      "source": [
        "# Drop empty values (otherwise the pipeline can't work with the data)\n",
        "#milk_rdd3 = milk_data.dropna(how='any', subset=inputColNames+[labelColName])\n",
        "milk_rdd3.show(5)\n",
        "\n",
        "# Uncomment the next line if you don't want to dropNA\n",
        "milk_rdd3 = milk_data \n",
        "\n",
        "\n",
        "\n",
        "### TEMPORARY FIX, BECAUSE REMOVING NA MAKES ALL VP COLLUMNS DISSAPEAR WHICH GIVES ERRORS ###\n",
        "#milk_rdd3 = milk_rdd3.drop('Period (VP = preperiod, HP = trial period)')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FGQ10MES4jFm"
      },
      "source": [
        "# Stages for pipeline\n",
        "\n",
        "# Index string columns\n",
        "index_strings = [StringIndexer(inputCol= col, outputCol= f'{col}_index') for col in stringColumn]\n",
        "\n",
        "# Encode string columns\n",
        "encoder = OneHotEncoderEstimator(inputCols=[string_indexer.getOutputCol() for string_indexer in index_strings], \n",
        "                                 outputCols= [f'{col}_encoded' for col in stringColumn])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ycr4ulh1ZbI6"
      },
      "source": [
        "index_strings = [StringIndexer(inputCol= col, outputCol= f'{col}_index') for col in stringColumn]\n",
        "\n",
        "# Encode string columns\n",
        "encoder = OneHotEncoderEstimator(inputCols=[string_indexer.getOutputCol() for string_indexer in index_strings], \n",
        "                                 outputCols= [f'{col}_encoded' for col in stringColumn])\n",
        "\n",
        "inputCols = doubleColumns + intColumns + [f'{col}_encoded' for col in stringColumn]\n",
        "# Vectorize input columns\n",
        "vectorizer = VectorAssembler(\n",
        "    inputCols = inputCols.remove(labelColName),\n",
        "    # inputCols = inputColNames,\n",
        "    outputCol = \"features\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6YNUG7MEvJJv"
      },
      "source": [
        "## Assembling the vectorizer\n",
        "vectorizer = VectorAssembler(\n",
        "    inputCols=inputColNames, \n",
        "    outputCol=\"features\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "buoMQkQtGRnD"
      },
      "source": [
        "## Splitting the dataset into a training and testing portion.\n",
        "\n",
        "# Setting a seed for reproducible results.\n",
        "ourSeed = 1234  # default = 1234\n",
        "\n",
        "# Randomly splitting the dataset (default 20% test, 80% train)\n",
        "(testSetDF, trainingSetDF) = milk_rdd3.randomSplit([2.0,8.0],seed=ourSeed)\n",
        "\n",
        "# Uncomment to cache these datasets for performance\n",
        "testSetDF.cache()\n",
        "trainingSetDF.cache()\n",
        "\n",
        "trainingSetDF.show(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OVIF87r80veI"
      },
      "source": [
        "### Linear Regression Machine Learning Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5RGiNe_0yYi"
      },
      "source": [
        "## Training a linear regression model with the default settings.\n",
        "\n",
        "# Initialize the linear regression learner with default values for the parameters\n",
        "lr = LinearRegression()\n",
        "\n",
        "# Setting the name of the column with the values that need to be learned\n",
        "# and setting the name of the column where the predicted results will be saved.\n",
        "lr.setLabelCol(labelColName)\\\n",
        "  .setPredictionCol(predictionColName)\n",
        "\n",
        "# Create a pipeline that performs the vectorizer and the Linear Regression\n",
        "# learning model.\n",
        "lrPipeline = Pipeline(stages = index_strings + [encoder] + [vectorizer] + [lr])\n",
        "\n",
        "# Uncomment the next line to show if the training set was created correctly\n",
        "#trainingSetDF.show(5)\n",
        "\n",
        "# Train the model on the training set with the default settings.\n",
        "lrModel = lrPipeline.fit(trainingSetDF)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9cpYGku4pmNH"
      },
      "source": [
        "## Inspecting the results of the previous model\n",
        "\n",
        "# The coefficients (i.e., weights) are as follows:\n",
        "weights = lrModel.stages[1].coefficients\n",
        "\n",
        "# The corresponding features for these weights are:\n",
        "featuresNoLabel = vectorizer.getInputCols()\n",
        "print(featuresNoLabel)\n",
        "\n",
        "# Print coefficients \n",
        "list(zip(featuresNoLabel, weights))\n",
        "print(list(zip(featuresNoLabel, weights)))\n",
        " \n",
        " # Print the intercept\n",
        "print(\"Intercept: \",lrModel.stages[1].intercept)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zMeIb7kUBSad"
      },
      "source": [
        "## Model Predictions:\n",
        "\n",
        " # Apply our LR model to the test data and predict power output\n",
        "predictionsLR = lrModel.transform(testSetDF).select(inputColNames+[labelColName]+[predictionColName])\n",
        "\n",
        " # Print the first 15 rows of your predictions\n",
        "predictionsLR.show(15)\n",
        "\n",
        "#Plotting predicted against actual values to show linearity\n",
        "sns.scatterplot(x=labelColName, y=predictionColName, data=predictionsLR.toPandas())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Yyx6H5QC-Qx"
      },
      "source": [
        "## Compute an evaluation metric for our test dataset\n",
        "\n",
        "# Create an RMSE evaluator using the label and predicted columns\n",
        "regEval = RegressionEvaluator(predictionCol=predictionColName, labelCol=labelColName, metricName=\"rmse\")\n",
        "\n",
        "# Run the evaluator on the DataFrame\n",
        "rmse = regEval.evaluate(predictionsLR)\n",
        "\n",
        "# Print the Root Mean Squared Error\n",
        "print(\"Root Mean Squared Error: %.2f\" % rmse)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bNt3i7O3DiHn"
      },
      "source": [
        "## Compute R-squared evaluation metric for our test dataset\n",
        "\n",
        "r2 = regEval.evaluate(predictionsLR, {regEval.metricName: \"r2\"})\n",
        "\n",
        "# Print R-squard\n",
        "print(\"r2: {0:.2f}\".format(r2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tALWfJ9w29bf"
      },
      "source": [
        "### Parameter Tuning and Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-6VStMZb3DMx"
      },
      "source": [
        "## Use paramater tuning to try to create a better linear regression model\n",
        "\n",
        "# We can reuse the RegressionEvaluator, regEval, to judge the model based on the best Root Mean Squared Error\n",
        "# Let's create our CrossValidator with 3 fold cross validation\n",
        "crossval = CrossValidator(estimator=lrPipeline, evaluator=regEval, numFolds=3)\n",
        "\n",
        "# Tune over our regularization parameter from 0.01 to 0.10\n",
        "regParam = [x / 100.0 for x in range(1, 11)]\n",
        "\n",
        "# Create a paramter grid using the ParamGridBuilder,\n",
        "# and add the grid to the CrossValidator\n",
        "paramGrid = (ParamGridBuilder()\n",
        "             .addGrid(lr.regParam, regParam)\n",
        "             .build())\n",
        "crossval.setEstimatorParamMaps(paramGrid)\n",
        "\n",
        "# Find and return the best model\n",
        "cvModel = crossval.fit(trainingSetDF).bestModel"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Gixa0vq6PGK"
      },
      "source": [
        "## Evaluate the new tuned model by comparing it to the default linear regression\n",
        "\n",
        "# Use cvModel to compute an evaluation metric for our test dataset: testSetDF\n",
        "predictionsRL = cvModel.transform(testSetDF).select(inputColNames+[labelColName]+[predictionColName])\n",
        "\n",
        "# Run the previously created RMSE evaluator, regEval, on the predictionsAndLabelsDF DataFrame\n",
        "rmseLR = regEval.evaluate(predictionsRL)\n",
        "\n",
        "# Compute the r2 evaluation metric for our test dataset\n",
        "r2LR = regEval.evaluate(predictionsRL, {regEval.metricName: \"r2\"})\n",
        "\n",
        "# Printing the rounded values to compare the 2 linear regression models.\n",
        "print(\"Original Root Mean Squared Error: {0:2.2f}\".format(rmse))\n",
        "print(\"New Root Mean Squared Error: {0:2.2f}\".format(rmseLR))\n",
        "print(\"Old r2: {0:2.2f}\".format(r2))\n",
        "print(\"New r2: {0:2.2f}\".format(r2LR))\n",
        "\n",
        "# Printing unrounded values for better testing purpose\n",
        "print(\"\\r\\n\",\"Un-rouned values printed above in same order:\\r\\n\",rmse,rmseLR,r2,r2LR)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CClquqzcs9lM"
      },
      "source": [
        "# Visualization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2N0JNXWVtI8Q"
      },
      "source": [
        "## Plotting sample of dataset against 1 column"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M9FkzfxCvcFR"
      },
      "source": [
        "## Copy of setting the correct columns to allow easier plotting\n",
        "\n",
        "### CHANGE inputColNames (list of x) AND LabelColName (y) TO CREATE THE\n",
        "### DESIRED PLOTS. # ONLY 10 x VALUES CAN BE ENTERED AT A TIME\n",
        "\n",
        "inputColNames = ['Protein preperiod (kg)','Fat preperiod (kg)','Crude fat (g/kg dm)','Protein%','Protein% preperiod','Fat%','Fat% preperiod']\n",
        "#inputColNames = doubleColumns[0:10]\n",
        "\n",
        "labelColName = \"Milk yield (kg)\"\n",
        "predictionColName = \"Predicted \" + labelColName\n",
        "\n",
        "# Removing the label column from the input column if it ended in there on accident\n",
        "if labelColName in inputColNames: inputColNames.remove(labelColName)\n",
        "\n",
        "# Drop empty values (otherwise it can't work with the data)\n",
        "# WE MIGHT NEED TO FIND AN ALTERNATIVE TO DROPPING ANY ROW WITH BLANKS!\n",
        "# CURRENTLY EXPERIMENTING WITH NOT DROPPING NA FOR THE PLOTTING\n",
        "#milk_rdd3 = milk_rdd2.dropna(how='any', subset=inputColNames+[labelColName])\n",
        "milk_rdd3 = milk_rdd2.select(inputColNames+[labelColName])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XOSmSbuQtdAD"
      },
      "source": [
        "## Plotting the columns versus the labelcolumn to get inital idea of linear regression\n",
        "\n",
        "### Trying to plot more than 10 plots at the same time results in empty plots ###\n",
        "\n",
        "milk_rdd3_sample = milk_rdd3.select(inputColNames+[labelColName]).sample(False,0.5)\n",
        "#print(milk_rdd3_sample)\n",
        "sns.set(rc={'figure.figsize':(10,10)})\n",
        "\n",
        "for column in inputColNames:\n",
        "  plt.figure()\n",
        "  sns.lmplot(x=column, y=labelColName,data=milk_rdd3_sample.toPandas())\n",
        "  plt.title(labelColName+\" vs \"+column)\n",
        "  plt.xlabel(column)\n",
        "  plt.ylabel(labelColName)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}