{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "melk.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOt2RGpR2K0K+RXLP5Scc15",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bartianbosch/Melk/blob/Bartian/melk.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 565
        },
        "id": "VZ2mPRZSHiRl",
        "outputId": "10f7d376-03bd-4091-9a34-019c88cd89aa"
      },
      "source": [
        "# To initialize Apache Spark, run this cell\n",
        "!apt-get update\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q http://downloads.apache.org/spark/spark-2.4.7/spark-2.4.7-bin-hadoop2.7.tgz\n",
        "!tar xf spark-2.4.7-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark\n",
        "\n",
        "import os\n",
        "import findspark\n",
        "from pyspark import SparkFiles\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql import types\n",
        "from pyspark.sql import functions as F\n",
        "from pyspark import SparkContext\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql import SQLContext\n",
        "from pyspark.ml.regression import LinearRegression\n",
        "from pyspark.ml.regression import LinearRegressionModel\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns \n",
        "\n",
        "# Initialise stuff\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-2.4.7-bin-hadoop2.7\"\n",
        "findspark.init()\n",
        "sp = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
        "sc = SparkContext.getOrCreate()\n",
        "spark = SparkSession.builder.getOrCreate()\n",
        "sqlContext = SQLContext(sc)\n",
        "\n",
        "plt.close('all')\n",
        "plt.rcParams['figure.figsize'] = [30, 20]\n",
        "\n",
        "# milk_data = spark.read.csv('/content/gdrive/MyDrive/Big_Data_Groupwork/ff_dairy_v1.csv', header=True, inferSchema = True)\n",
        "url = 'https://raw.githubusercontent.com/bartianbosch/Melk/main/ff_dairy_v1_preprocessed.csv'\n",
        "fileName = url.split('/')[-1]\n",
        "spark.sparkContext.addFile(url)\n",
        "milk_data = spark.read.csv(SparkFiles.get(fileName), header=True)\n",
        "\n",
        "def fixType(datasetName, colName, dataType):\n",
        "  \"\"\"Takes a dataset and returns the dataset with the given column set to the given dataype\"\"\"\n",
        "  return datasetName.withColumn(colName, F.col(colName).cast(dataType))\n",
        "\n",
        "# Preparing Lists with the colum names and which type they need to be\n",
        "allColumns = ['Cow number', 'Date', 'Barn', 'Barn part', 'Treatment', 'Lactation number', 'Days in milk', 'Day number', 'Week', 'Period (VP = preperiod, HP = trial period)', 'Period part (VP = preperiod, HP = trial period)', 'Intake basal ration (kg dm)', 'Intake total ration (kg dm)', 'Water intake (kg)', 'Concentrate intake (kg)', 'Weight (kg)', 'BCS', 'Backfat Thickness', 'Milk yield (kg)', 'Fat%', 'Protein%', 'Urea (mg/kg)', 'SCC (*1000/ml)', 'Lactose%', 'Avg Temperature (degC)', 'Air speed', 'Max temperature (degC)', 'Rumination time (min/day)', 'Avg pH', 'Avg Rumen Temperature ', 'Time pH<5,8 (h)', 'Manure consistency (1=fluid, 5= hard)', 'Manure fibre score (1=short, 5 = long)', 'Number of kernels', 'Manure sieving residu (%)', 'Manure dm (g/kg OM)', 'Manure starch (g/kg dm)', 'Urin-pH', 'Intake pre-period (kg dm)', 'Milk yield prepreriod (kg)', 'Fat% preperiod', 'Protein% preperiod', 'Fat preperiod (kg)', 'Protein preperiod (kg)', 'ECM preperiod (kg)', 'ECM (kg)', 'Crude fiber (g/day)', 'Sugar (g/day)', 'Crude protein (g/day)', 'Crude fat (g/day)', 'Starch (g/day)', 'Ca (g/day)', 'P (g/day)', 'Na (g/day)', 'Cl (g/day)', 'K (g/day)', 'Mg (g/day)', 'nXP (g/day)', 'RNB (g/day)', 'MELK (g/day)', 'NEL (g/day)', 'WDE (g/day)', 'EKB (g/day)', 'WDS (g/day)', 'SPK (g/day)', 'TPK (g/day)', 'SPE (g/day)', 'TPE (g/day)', 'plusI (/day)', 'WI (/day)', 'GP (g/day)', 'Crude fiber (g/kg dm)', 'Sugar (g/kg dm)', 'Crude protein (g/kg dm)', 'Crude fat (g/kg dm)', 'Starch (g/kg dm)', 'Ca (g/kg dm)', 'P (g/kg dm)', 'Na (g/kg dm)', 'Cl (g/kg dm)', 'K (g/kg dm)', 'Mg (g/kg dm)', 'nXP (g/kg dm)', 'RNB (g/kg dm)', 'MELK (/kg dm)', 'NEL (MJ/kg dm)', 'WDE (g/kg dm)', 'EKB (g/kg dm)', 'WDS (g/kg dm)', 'SPK (g/kg dm)', 'TPK (g/kg dm)', 'SPE (g/kg dm)', 'TPE (g/kg dm)', 'plusI (/kg dm)', 'WI (/kg dm)', 'GP (g/kg dm)']\n",
        "doubleColumns = ['Intake basal ration (kg dm)', 'Intake total ration (kg dm)', 'Water intake (kg)', 'Concentrate intake (kg)', 'Weight (kg)', 'BCS', 'Milk yield (kg)', 'Fat%', 'Protein%', 'Lactose%', 'Avg Temperature (degC)', 'Air speed', 'Max temperature (degC)', 'Avg pH', 'Avg Rumen Temperature ', 'Time pH<5,8 (h)', 'Number of kernels', 'Manure sieving residu (%)', 'Manure starch (g/kg dm)', 'Urin-pH', 'Intake pre-period (kg dm)', 'Milk yield prepreriod (kg)', 'Fat% preperiod', 'Protein% preperiod', 'Fat preperiod (kg)', 'Protein preperiod (kg)', 'ECM preperiod (kg)', 'ECM (kg)']\n",
        "intColumns = ['Cow number', 'Barn', 'Barn part', 'Lactation number', 'Days in milk', 'Day number', 'Week', 'Backfat Thickness', 'Urea (mg/kg)', 'SCC (*1000/ml)', 'Rumination time (min/day)', 'Manure consistency (1=fluid, 5= hard)', 'Manure fibre score (1=short, 5 = long)', 'Manure dm (g/kg OM)', 'Crude fiber (g/day)', 'Sugar (g/day)', 'Crude protein (g/day)', 'Crude fat (g/day)', 'Starch (g/day)', 'Ca (g/day)', 'P (g/day)', 'Na (g/day)', 'Cl (g/day)', 'K (g/day)', 'Mg (g/day)', 'nXP (g/day)', 'RNB (g/day)', 'MELK (g/day)', 'NEL (g/day)', 'WDE (g/day)', 'EKB (g/day)', 'WDS (g/day)', 'SPK (g/day)', 'TPK (g/day)', 'SPE (g/day)', 'TPE (g/day)', 'plusI (/day)', 'WI (/day)', 'GP (g/day)', 'Crude fiber (g/kg dm)', 'Sugar (g/kg dm)', 'Crude protein (g/kg dm)', 'Crude fat (g/kg dm)', 'Starch (g/kg dm)', 'Ca (g/kg dm)', 'P (g/kg dm)', 'Na (g/kg dm)', 'Cl (g/kg dm)', 'K (g/kg dm)', 'Mg (g/kg dm)', 'nXP (g/kg dm)', 'RNB (g/kg dm)', 'MELK (/kg dm)', 'NEL (MJ/kg dm)', 'WDE (g/kg dm)', 'EKB (g/kg dm)', 'WDS (g/kg dm)', 'SPK (g/kg dm)', 'TPK (g/kg dm)', 'SPE (g/kg dm)', 'TPE (g/kg dm)', 'plusI (/kg dm)', 'WI (/kg dm)', 'GP (g/kg dm)']\n",
        "stringColumn = ['Treatment', 'Period (VP = preperiod, HP = trial period)', 'Period part (VP = preperiod, HP = trial period)']\n",
        "milk_rdd2 = milk_data\n",
        "\n",
        "# Setting the columns to the correct type\n",
        "for colName in doubleColumns:\n",
        "  milk_rdd2 = fixType(milk_rdd2, colName, \"double\")\n",
        "for colName in intColumns:\n",
        "  milk_rdd2 = fixType(milk_rdd2, colName, \"int\")\n",
        "milk_data = milk_rdd2.withColumn(\"Date\", F.col(\"Date\").cast(\"date\"))\n",
        "\n",
        "# milk_data.printSchema()\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Hit:1 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease\n",
            "Ign:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:3 http://security.ubuntu.com/ubuntu bionic-security InRelease\n",
            "Ign:4 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "Hit:6 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Hit:7 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n",
            "Hit:8 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Hit:9 http://archive.ubuntu.com/ubuntu bionic-updates InRelease\n",
            "Hit:12 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Hit:13 http://archive.ubuntu.com/ubuntu bionic-backports InRelease\n",
            "Reading package lists... Done\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-bc13ceb4101c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfindspark\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSparkFiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSparkSession\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pyspark'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XZoKULzabvt4"
      },
      "source": [
        "milk_data.printSchema()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "odJJ8ZTnIEqt",
        "outputId": "b54d4dd8-ee53-4273-f259-6749af5568d2"
      },
      "source": [
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.regression import LinearRegression, LinearRegressionModel\n",
        "from pyspark.ml.feature import StringIndexer, OneHotEncoderEstimator\n",
        "\n",
        "features_cols = ['Crude fiber (g/day)', 'Sugar (g/day)', 'Crude protein (g/day)', 'Crude fat (g/day)', 'Starch (g/day)', \n",
        "                             'Ca (g/day)', 'P (g/day)', 'Na (g/day)', 'Cl (g/day)', 'K (g/day)', 'Mg (g/day)']\n",
        "# features_cols = ['Cow number', 'Date', 'Barn', 'Barn part', 'Treatment', 'Lactation number', 'Days in milk', 'Day number', 'Week', 'Period (VP = preperiod, HP = trial period)', 'Period part (VP = preperiod, HP = trial period)', 'Intake basal ration (kg dm)', 'Intake total ration (kg dm)', 'Water intake (kg)', 'Concentrate intake (kg)', 'Weight (kg)', 'BCS', 'Backfat Thickness', 'Milk yield (kg)', 'Fat%', 'Protein%', 'Urea (mg/kg)', 'SCC (*1000/ml)', 'Lactose%', 'Avg Temperature (degC)', 'Air speed', 'Max temperature (degC)', 'Rumination time (min/day)', 'Avg pH', 'Avg Rumen Temperature ', 'Time pH<5,8 (h)', 'Manure consistency (1=fluid, 5= hard)', 'Manure fibre score (1=short, 5 = long)', 'Number of kernels', 'Manure sieving residu (%)', 'Manure dm (g/kg OM)', 'Manure starch (g/kg dm)', 'Urin-pH', 'Intake pre-period (kg dm)', 'Milk yield prepreriod (kg)', 'Fat% preperiod', 'Protein% preperiod', 'Fat preperiod (kg)', 'Protein preperiod (kg)', 'ECM preperiod (kg)', 'ECM (kg)', 'Crude fiber (g/day)', 'Sugar (g/day)', 'Crude protein (g/day)', 'Crude fat (g/day)', 'Starch (g/day)', 'Ca (g/day)', 'P (g/day)', 'Na (g/day)', 'Cl (g/day)', 'K (g/day)', 'Mg (g/day)', 'nXP (g/day)', 'RNB (g/day)', 'MELK (g/day)', 'NEL (g/day)', 'WDE (g/day)', 'EKB (g/day)', 'WDS (g/day)', 'SPK (g/day)', 'TPK (g/day)', 'SPE (g/day)', 'TPE (g/day)', 'plusI (/day)', 'WI (/day)', 'GP (g/day)', 'Crude fiber (g/kg dm)', 'Sugar (g/kg dm)', 'Crude protein (g/kg dm)', 'Crude fat (g/kg dm)', 'Starch (g/kg dm)', 'Ca (g/kg dm)', 'P (g/kg dm)', 'Na (g/kg dm)', 'Cl (g/kg dm)', 'K (g/kg dm)', 'Mg (g/kg dm)', 'nXP (g/kg dm)', 'RNB (g/kg dm)', 'MELK (/kg dm)', 'NEL (MJ/kg dm)', 'WDE (g/kg dm)', 'EKB (g/kg dm)', 'WDS (g/kg dm)', 'SPK (g/kg dm)', 'TPK (g/kg dm)', 'SPE (g/kg dm)', 'TPE (g/kg dm)', 'plusI (/kg dm)', 'WI (/kg dm)', 'GP (g/kg dm)']\n",
        "\n",
        "predictionColName = 'predProtein'\n",
        "labelColName = \"Milk yield (kg)\"\n",
        "\n",
        "\n",
        "milk_data = milk_data.select(allColumns).dropna(how='any')\n",
        "\n",
        "# Split dataset into test and training data\n",
        "test_data, train_data = milk_data.randomSplit([0.8, 0.2], 0)\n",
        "\n",
        "# Stages\n",
        "# index_strings = [StringIndexer(inputCol= col, outputCol= f'{col}_index') for col in stringColumn]\n",
        "\n",
        "# encoder = OneHotEncoderEstimator(inputCols=[string_indexer.getOutputCol() for string_indexer in index_strings], \n",
        "                                #  outputCols= [f'{col}_encoded' for col in stringColumn])\n",
        "\n",
        "vectorizer = VectorAssembler(\n",
        "    # inputCols = doubleColumns + intColumns + [f'{col}_encoded' for col in stringColumn],\n",
        "    inputCols = [\"labelColName\"] + features_cols,\n",
        "    outputCol = \"features\")\n",
        "\n",
        "lr = LinearRegression(featuresCol = 'features', labelCol=labelColName, predictionCol = predictionColName)\n",
        "\n",
        "# Create pipeline\n",
        "lr_pipeline = Pipeline(stages = [vectorizer] + [lr]) #index_strings + [encoder] + \n",
        "\n",
        "# Fit pipeline\n",
        "lr_model = lr_pipeline.fit(train_data)\n",
        "\n",
        "# vectorized = vectorizer.transform(nutrients) #.select('features', 'Protein%')\n",
        "\n",
        "\n",
        "# lrModel = lr.fit(train_data)\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-6391ee2e679b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mml\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregression\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLinearRegression\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLinearRegressionModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStringIndexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOneHotEncoderEstimator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m features_cols = ['Crude fiber (g/day)', 'Sugar (g/day)', 'Crude protein (g/day)', 'Crude fat (g/day)', 'Starch (g/day)', \n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pyspark'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WcD5Bv5TXilt",
        "outputId": "0024d714-0d1f-4232-e9df-6e1b0c53091c"
      },
      "source": [
        "# Inspecting the results of the previous model\n",
        "\n",
        "# The coefficients (i.e., weights) are as follows:\n",
        "weights = lrModel.coefficients\n",
        "\n",
        "# Print coefficients \n",
        "list(zip(features_cols, weights))\n",
        "print(list(zip(features_cols, weights)))\n",
        " \n",
        " # Print the intercept\n",
        "print(\"Intercept: \",lrModel.intercept)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('Crude fiber (g/day)', -0.003975544125964483), ('Sugar (g/day)', 0.015414138197454961), ('Crude protein (g/day)', -0.02881282320707079), ('Crude fat (g/day)', 0.040742235016491345), ('Starch (g/day)', 0.009536090850106057), ('Ca (g/day)', 0.049188047500887025), ('P (g/day)', -0.02280844594882234), ('Na (g/day)', 0.02001380902446119), ('Cl (g/day)', -0.05095530326516728), ('K (g/day)', 0.061875393019701554), ('Mg (g/day)', 0.02887785949633683)]\n",
            "Intercept:  3.0737620136490027\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vyAdt1gnKvnD",
        "outputId": "d52a5c98-927d-483b-ad04-3d2ab21db37f"
      },
      "source": [
        "# Model Predictions:\n",
        "\n",
        " # Apply our LR model to the test data and predict output\n",
        "predictionsLR = lrModel.transform(test_data).select(features_cols + labelColName + predictionColName)\n",
        "\n",
        " # Print the first 15 rows of your predictions\n",
        "predictionsLR.show(15)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------------------+-------------+---------------------+-----------------+--------------+----------+---------+----------+----------+---------+----------+--------+------------------+\n",
            "|Crude fiber (g/day)|Sugar (g/day)|Crude protein (g/day)|Crude fat (g/day)|Starch (g/day)|Ca (g/day)|P (g/day)|Na (g/day)|Cl (g/day)|K (g/day)|Mg (g/day)|Protein%|       predProtein|\n",
            "+-------------------+-------------+---------------------+-----------------+--------------+----------+---------+----------+----------+---------+----------+--------+------------------+\n",
            "|               4516|         1000|                 3749|              865|          5346|       137|      100|        48|       126|      374|        82|    2.44| 3.244637711442318|\n",
            "|               3704|          825|                 3090|              712|          4402|       113|       83|        40|       103|      307|        68|     2.5| 3.196474709350346|\n",
            "|               3686|          817|                 3063|              706|          4367|       112|       82|        39|       103|      305|        67|    2.52|3.1454289786640413|\n",
            "|               2555|          648|                 2356|              531|          3312|        88|       65|        31|        71|      220|        49|    2.54|3.1154588582008174|\n",
            "|               4221|          985|                 3649|              834|          5174|       134|       99|        47|       118|      355|        78|    2.54|3.1360055798009783|\n",
            "|                  0|            0|                    0|                0|             0|         0|        0|         0|         0|        0|         0|    2.55|3.0737620136490027|\n",
            "|               3317|          810|                 2971|              673|          4192|       110|       81|        39|        92|      283|        62|    2.55|3.1212686174492763|\n",
            "|               4272|         1307|                 4579|             1001|          6322|       175|      129|        62|       117|      392|        88|    2.56| 3.113852434453394|\n",
            "|               3052|          872|                 3095|              684|          4300|       117|       86|        41|        84|      274|        61|    2.57| 3.127924448646853|\n",
            "|               3697|          933|                 3397|              766|          4778|       126|       93|        44|       103|      318|        70|    2.57|3.0589450058474643|\n",
            "|               2983|          716|                 2635|              599|          3725|        97|       71|        34|        83|      253|        56|    2.58| 3.130639722988372|\n",
            "|               2924|          923|                 3283|              678|          4757|       125|       92|        42|        79|      270|        60|     2.6|3.3747090884000297|\n",
            "|               3478|         1025|                 3617|              795|          5011|       137|      101|        49|        96|      315|        70|     2.6| 3.042033705435463|\n",
            "|                  0|            0|                    0|                0|             0|         0|        0|         0|         0|        0|         0|    2.65|3.0737620136490027|\n",
            "|               4036|         1059|                 3823|              857|          5357|       143|      105|        50|       112|      352|        78|    2.65|3.1668610820548246|\n",
            "+-------------------+-------------+---------------------+-----------------+--------------+----------+---------+----------+----------+---------+----------+--------+------------------+\n",
            "only showing top 15 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8FbVbCsrYC6N",
        "outputId": "9ce6a6c2-3e99-4953-e1c2-d4dffcaf919c"
      },
      "source": [
        "# Now let's compute an evaluation metric for our test dataset\n",
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "\n",
        " # Create an RMSE evaluator using the label and predicted columns\n",
        "regEval = RegressionEvaluator(predictionCol=predictionColName, labelCol=labelColName, metricName=\"rmse\")\n",
        "\n",
        " # Run the evaluator on the DataFrame\n",
        "rmse = regEval.evaluate(predictionsLR)\n",
        "\n",
        "print(\"Root Mean Squared Error: %.2f\" % rmse)\n",
        "\n",
        "# Now let's compute another evaluation metric for our test dataset\n",
        "r2 = regEval.evaluate(predictionsLR, {regEval.metricName: \"r2\"})\n",
        "\n",
        "print(\"r2: {0:.2f}\".format(r2))"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Root Mean Squared Error: 0.24\n",
            "r2: 0.10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7c2p-QIoaI9c"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}